{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task #1: Import Dataset and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.0\n",
      "  Downloading numpy-1.26.0-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "Downloading numpy-1.26.0-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 10.7/15.8 MB 61.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 62.2 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.26.0\n",
      "Collecting pandas==2.1.1\n",
      "  Downloading pandas-2.1.1-cp39-cp39-win_amd64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in \\\\ps-home.insa-lyon.fr\\users\\home\\abouziane\\tp data mining\\.venv\\lib\\site-packages (from pandas==2.1.1) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in \\\\ps-home.insa-lyon.fr\\users\\home\\abouziane\\tp data mining\\.venv\\lib\\site-packages (from pandas==2.1.1) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas==2.1.1)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas==2.1.1)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in \\\\ps-home.insa-lyon.fr\\users\\home\\abouziane\\tp data mining\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas==2.1.1) (1.17.0)\n",
      "Downloading pandas-2.1.1-cp39-cp39-win_amd64.whl (10.8 MB)\n",
      "   ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 8.9/10.8 MB 55.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.8/10.8 MB 51.8 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.1.1 pytz-2024.2 tzdata-2024.2\n",
      "Collecting scikit-learn==1.5.1\n",
      "  Downloading scikit_learn-1.5.1-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in \\\\ps-home.insa-lyon.fr\\users\\home\\abouziane\\tp data mining\\.venv\\lib\\site-packages (from scikit-learn==1.5.1) (1.26.0)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn==1.5.1)\n",
      "  Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn==1.5.1)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.5.1)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.1-cp39-cp39-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 6.0/11.0 MB 30.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 38.2 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 24.6/46.2 MB 111.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.1/46.2 MB 113.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 95.0 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.1 scipy-1.13.1 threadpoolctl-3.5.0\n",
      "Collecting scipy==1.12.0\n",
      "  Downloading scipy-1.12.0-cp39-cp39-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in \\\\ps-home.insa-lyon.fr\\users\\home\\abouziane\\tp data mining\\.venv\\lib\\site-packages (from scipy==1.12.0) (1.26.0)\n",
      "Downloading scipy-1.12.0-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 13.4/46.2 MB 70.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 38.0/46.2 MB 96.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 89.2 MB/s eta 0:00:00\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.13.1\n",
      "    Uninstalling scipy-1.13.1:\n",
      "      Successfully uninstalled scipy-1.13.1\n",
      "Successfully installed scipy-1.12.0\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pip install numpy==1.26.0\n",
    "# data frames\n",
    "! pip install pandas==2.1.1\n",
    "# machine learning algorithms\n",
    "! pip install scikit-learn==1.5.1\n",
    "! pip install scipy==1.12.0\n",
    "# plotting\n",
    "! pip install plotly==5.24.1\n",
    "! pip install matplotlib==3.8.0\n",
    "! pip install seaborn==0.13.2\n",
    "! pip install plotly-express==0.4.1\n",
    "! pip install chart-studio==1.1.0\n",
    "# web app library\n",
    "! pip install streamlit==1.37.1\n",
    "# association rules\n",
    "! pip install mlxtend==0.23.3\n",
    "\n",
    "! pip install nbformat==5.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T07:39:29.594195Z",
     "start_time": "2025-01-16T07:39:29.590562Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# load pandas to deal with the data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mpandas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# plotting\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# load pandas to deal with the data\n",
    "import pandas as pd\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T07:48:55.223608Z",
     "start_time": "2025-01-16T07:48:55.219362Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "def load_dataset(path):\n",
    "    try:\n",
    "        df = pd.read_csv(path, low_memory=False)\n",
    "        if df is not None and not df.empty: \n",
    "            return df\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T07:48:58.815614Z",
     "start_time": "2025-01-16T07:48:57.511229Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"flickr_data2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.111721Z",
     "start_time": "2025-01-09T10:22:24.105300Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T07:49:04.250030Z",
     "start_time": "2025-01-16T07:49:04.237203Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.136566Z",
     "start_time": "2025-01-09T10:22:24.124165Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many distinct flower classes exist in the dataframe? What are they? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.145891Z",
     "start_time": "2025-01-09T10:22:24.137771Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "data['class'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.155759Z",
     "start_time": "2025-01-09T10:22:24.145891Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "data['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How many samples exist in the dataframe?\n",
    "150\n",
    "\n",
    "* What are the features? What are their types?\n",
    "Index(['sepal length', 'sepal width', 'petal length', 'petal width', 'class'], dtype='object')\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 150 entries, 0 to 149\n",
    "Data columns (total 5 columns):\n",
    " #   Column        Non-Null Count  Dtype  \n",
    "---  ------        --------------  -----  \n",
    " 0   sepal length  150 non-null    float64\n",
    " 1   sepal width   150 non-null    float64\n",
    " 2   petal length  150 non-null    float64\n",
    " 3   petal width   150 non-null    float64\n",
    " 4   class         150 non-null    object \n",
    "dtypes: float64(4), object(1)\n",
    "memory usage: 6.0+ KB\n",
    "\n",
    "* How many distinct flower classes exist in the dataframe? What are they? \n",
    "3\n",
    "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task #2: Perform Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will explore the most common **data quality issues**:\n",
    "* [missing values](#missing-vals)\n",
    "* [duplicates](#duplicates)\n",
    "\n",
    "Second, we will use [**descriptive statistics**](#desc-stats) to have get a statistical summary of the data. \n",
    "\n",
    "We will then use [**data visualisaiton**](#data-vis) to get a better understanding of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"missing-vals\"></a>\n",
    "### Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the missing values, several approaches can be used:\n",
    "\n",
    "1. The `info()` mwthods provides a summary of a dataframe in terms of the types of values, non-null values and memory usage. Thus, by comparing the number of non-null values of each column with the total number of entries, one can have an idea of missing values.\n",
    "2. Using the [`isna()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html) method. By summing the resulting values, we obtain the number of null values for each column.\n",
    "3. To get the rows with any missing values, you can use `isna()` followed by `any(axis=1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.165895Z",
     "start_time": "2025-01-09T10:22:24.155759Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# method 1: info()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are as many non-null values for each of the attributes (`150 non-null`) than the total number of rows (see `RangeIndes: 150 entries`), it means that there is no *missin values* in our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.174599Z",
     "start_time": "2025-01-09T10:22:24.167297Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# method 2: using isna() \n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can see that there is no missing values in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.185562Z",
     "start_time": "2025-01-09T10:22:24.174599Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# method 3: get the rwos with missing values\n",
    "data[data.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return DataFrame is empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To **remove** the rows with missing values, you can use the [`dropna()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) method. Check the parameters for more details.\n",
    "\n",
    "*Tip*: keep a track of the number of rows in the initial DataFrame and during and after the cleaning:\n",
    "```\n",
    "print(f\"Before: {len(df)}\")\n",
    "df_cleaned = df.dropna()\n",
    "print(f\"After: {len(df_cleaned)}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.193501Z",
     "start_time": "2025-01-09T10:22:24.185562Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "print(f\"Initial: {len(data)}\")\n",
    "data_cleaned = data.dropna()\n",
    "print(f\"After removing missing values: {len(data_cleaned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"duplicates\"></a>\n",
    "### Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check duplicated values, you can use the [`duplicated()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html) method. You can specify the paramater `keep` (`'first'`, `'last'`, `False`) to determine which duplicates (if any) to be maked as `True` in the resulting boolean Series indicating duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.204263Z",
     "start_time": "2025-01-09T10:22:24.193501Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# check the duplicates\n",
    "data_cleaned.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.214358Z",
     "start_time": "2025-01-09T10:22:24.204263Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# check the duplicates of the class column and keep the last occurence\n",
    "data_cleaned['class'].duplicated(keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.224198Z",
     "start_time": "2025-01-09T10:22:24.214358Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# another option using subset parameter\n",
    "data_cleaned.duplicated(subset=['class'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.233025Z",
     "start_time": "2025-01-09T10:22:24.224198Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# count the number of duplicates\n",
    "data_cleaned.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is one case of duplicates. Let's check the corresponding rows. We set the parameter `keep=False` to display all rows and not just the second occurence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.246461Z",
     "start_time": "2025-01-09T10:22:24.233025Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "data_cleaned[data_cleaned.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can keep these rows or we can drop them (or any of them) using [`drop_duplicates`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html). Let's keep the first occurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.252584Z",
     "start_time": "2025-01-09T10:22:24.246461Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# remove duplicates\n",
    "data_cleaned = data_cleaned.drop_duplicates(keep='first')\n",
    "# show the stats\n",
    "print(f\"Initial: {len(data)}\")\n",
    "print(f\"After removing duplicates: {len(data_cleaned)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the cleaned DataFrame to `data/processed/data_cleaned.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.262407Z",
     "start_time": "2025-01-09T10:22:24.252584Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# save to file\n",
    "data_cleaned.to_csv('../data/processed/data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='desc-stats'></a>\n",
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the statistical summary of the dataframe, we can use [`describe()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html). For different columns, it displays the count, the average value, the standard deviation, the min and max values, percentiles. \n",
    "By default, in mixed data types DataFrames, it displays the values for quantative data only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.278082Z",
     "start_time": "2025-01-09T10:22:24.262407Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# summarised statistics\n",
    "data_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.293480Z",
     "start_time": "2025-01-09T10:22:24.278082Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# summarised statistics with object data\n",
    "data_cleaned.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the range of values of the quantative attributes, we can see that their scales are comparable. So there is no need to scale them for futher use in algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the number of values for `class` column, we can use [`value_counts()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.299468Z",
     "start_time": "2025-01-09T10:22:24.293480Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "print(data_cleaned['class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Select the samples with the largest `sepal length`. Which type of iris flower it belongs to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:24.309326Z",
     "start_time": "2025-01-09T10:22:24.299468Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "max_sepal_length_index = data['sepal length'].idxmax()\n",
    "max_sepal_length_sample = data.loc[max_sepal_length_index]\n",
    "\n",
    "iris_type = max_sepal_length_sample['class']\n",
    "\n",
    "print(\"Sample with the largest sepal length:\")\n",
    "print(max_sepal_length_sample)\n",
    "print(f\"\\nThe flower type is: {iris_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data-vis'></a>\n",
    "### Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Pairplot](#pairplot)\n",
    "* [Correlation analysis](#correlation)\n",
    "* [Class-wise boxplot](#boxplot)\n",
    "* [Scatter plot with PCA](#pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pairplot'></a>\n",
    "#### Pairplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS:**\n",
    "\n",
    "- Let's start by plotting a pairplot using [`seaborn.pairplot()`](https://seaborn.pydata.org/generated/seaborn.pairplot.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:26.865758Z",
     "start_time": "2025-01-09T10:22:24.309326Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "# select columns to plot\n",
    "cols = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class']\n",
    "# Plot the pairplot\n",
    "sns.pairplot(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot, we can observe the following:\n",
    "* there is a strong positive linear relationship between `petal width` and `petal length`\n",
    "* we can observe two distinct groups, see `sepal length` vs. `petal length` for example or `petal length` vs. `petal width`. This can already give us an initial idea about a potential number of clusters and which features may influence more the separation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make use of the `class` column to have a look on the data through the class labels. We will assign colors based on the value of `class`. To do so, we will assign the value to `hue` parameter. Mind that by default, the diagonal elements will disply a layered kernel density estimate (KDE). To change that, you can assign value to the `diag_kind` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:29.752443Z",
     "start_time": "2025-01-09T10:22:26.867424Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Plot the pairplot\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "# pair plot\n",
    "g = sns.pairplot(data=data_cleaned[cols], hue='class', diag_kind='hist')\n",
    "# add a title to the figure\n",
    "g.figure.suptitle('Pairplot', y=1.04)\n",
    "# Remove the default legend\n",
    "g._legend.remove() \n",
    "# Add new legend\n",
    "g.add_legend(loc='upper right')\n",
    "# Adjust the layout to prevent title overlap\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using colors, we can see that a groups that stands apart corresponds to `Iris-setosa`. We can also observe that some values of `Iris-versicolor` and `Iris-virginica` are similar. This implied that a separation of the entries of these two classes might be difficult.\n",
    "\n",
    "**Note**: in this use case, there are true class labels which is not usually the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='correlation'></a>\n",
    "#### Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**\n",
    "\n",
    "* Plot the correlation matrix and comment on the result.\n",
    "\n",
    "*Hint*: to calculate correlations, use the [`corr()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) method of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:29.762936Z",
     "start_time": "2025-01-09T10:22:29.752443Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "features = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "# ANSWER\n",
    "corr = data[features].corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR COMMENT: \n",
    "* Petal Length and Petal Width (0.96) have the strongest positive correlation that indicates that the features are highly related(as the petal length increases, the petal width also tends to increase)\n",
    "* Pairs \"Petal length and sepal length\"(0.87 and \"petal width and sepal length\" suggest that flowers with longer sepals tend to have both wider and longer petals\n",
    "* Pairs \"Sepal Width and Petal Length\" (-0.43) and \"Sepal Width and Petal Width\" (-0.37) suggest that as petal dimensions increase, sepal width tends to decrease\n",
    "* \"Sepal length and sepal width\" (-0.12) appear to be independent of each other "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualise this correlation matrix using a heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:29.969237Z",
     "start_time": "2025-01-09T10:22:29.763974Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Create heatmap\n",
    "sns.heatmap(\n",
    "        corr,\n",
    "        annot=True,  # Show correlation values\n",
    "        cmap='coolwarm',  # Color scheme: red for positive, blue for negative\n",
    "        vmin=-1, vmax=1,  # Fix scale between -1 and 1\n",
    "        center=0,  # Center colormap at 0\n",
    "        fmt='.2f'  # Format correlation values to 2 decimal places\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='boxplot'></a>\n",
    "#### Class-wise Boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display boxplots of each feature using [`seaborn.boxplot()`](https://seaborn.pydata.org/generated/seaborn.boxplot.html#seaborn.boxplot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:30.800189Z",
     "start_time": "2025-01-09T10:22:29.969237Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(4, 1, figsize=(8, 16))\n",
    "fig.suptitle('Iris Features Distribution by Class')\n",
    "\n",
    "for ax, feature in zip(axes, features):\n",
    "    sns.boxplot(data=data_cleaned, x='class', y=feature, ax=ax, hue='class')\n",
    "    ax.set_title(feature)\n",
    "    \n",
    "    for class_name in data_cleaned['class'].unique():\n",
    "        class_data = data_cleaned[data_cleaned['class'] == class_name][feature]\n",
    "        \n",
    "        # Calculate median, IQR, and outliers\n",
    "        median = class_data.median()\n",
    "        q1 = class_data.quantile(0.25)\n",
    "        q3 = class_data.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_whisker = q1 - 1.5 * iqr\n",
    "        upper_whisker = q3 + 1.5 * iqr\n",
    "        \n",
    "        # Identify outliers\n",
    "        outliers = class_data[(class_data < lower_whisker) | (class_data > upper_whisker)]\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"Feature: {feature} - Class: {class_name}\")\n",
    "        print(f\"  Median: {median}\")\n",
    "        print(f\"  IQR: {iqr} (Q1: {q1}, Q3: {q3})\")\n",
    "        print(f\"  Outliers: {outliers.tolist()}\")\n",
    "        print()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:**\n",
    "\n",
    "* Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature: **Sepal Length**\n",
    "\n",
    "- **Class: Iris-setosa**\n",
    "  - Median: 5.0\n",
    "  - IQR: 0.40 (Q1: 4.8, Q3: 5.2)\n",
    "  - Outliers: None\n",
    "  - **Comment:** The sepal length for Iris-setosa is relatively consistent with a narrow IQR, indicating little variation within the class.\n",
    "  \n",
    "- **Class: Iris-versicolor**\n",
    "  - Median: 5.9\n",
    "  - IQR: 0.70 (Q1: 5.6, Q3: 6.3)\n",
    "  - Outliers: None\n",
    "  - **Comment:** Iris-versicolor has a higher median compared to Iris-setosa, with a moderate IQR suggesting moderate variation within the class.\n",
    "\n",
    "- **Class: Iris-virginica**\n",
    "  - Median: 6.5\n",
    "  - IQR: 0.60 (Q1: 6.3, Q3: 6.9)\n",
    "  - Outliers: [4.9, 7.9]\n",
    "  - **Comment:** The median for Iris-virginica is the highest, but it shows a few outliers, which could indicate some variance within the class.\n",
    "\n",
    "---\n",
    "\n",
    "### Feature: **Sepal Width**\n",
    "\n",
    "- **Class: Iris-setosa**\n",
    "  - Median: 3.4\n",
    "  - IQR: 0.48 (Q1: 3.2, Q3: 3.68)\n",
    "  - Outliers: [4.4, 2.3]\n",
    "  - **Comment:** Iris-setosa shows some outliers, which could be due to varying environmental factors or measurement errors.\n",
    "  \n",
    "- **Class: Iris-versicolor**\n",
    "  - Median: 2.8\n",
    "  - IQR: 0.48 (Q1: 2.53, Q3: 3.0)\n",
    "  - Outliers: None\n",
    "  - **Comment:** The sepal width for Iris-versicolor is smaller with a narrow IQR, suggesting less variation and a more consistent distribution.\n",
    "\n",
    "- **Class: Iris-virginica**\n",
    "  - Median: 3.0\n",
    "  - IQR: 0.40 (Q1: 2.8, Q3: 3.2)\n",
    "  - Outliers: None\n",
    "  - **Comment:** Iris-virginica has a sepal width median slightly larger than Iris-versicolor, with no outliers, indicating consistent distribution.\n",
    "\n",
    "---\n",
    "\n",
    "### Feature: **Petal Length**\n",
    "\n",
    "- **Class: Iris-setosa**\n",
    "  - Median: 1.5\n",
    "  - IQR: 0.18 (Q1: 1.4, Q3: 1.58)\n",
    "  - Outliers: [1.1, 1.0, 1.9, 1.9]\n",
    "  - **Comment:** Petal length for Iris-setosa shows some outliers, indicating some abnormal data points, but the IQR is small, showing relatively uniform petal lengths within the class.\n",
    "\n",
    "- **Class: Iris-versicolor**\n",
    "  - Median: 4.35\n",
    "  - IQR: 0.60 (Q1: 4.0, Q3: 4.6)\n",
    "  - Outliers: [3.0]\n",
    "  - **Comment:** Iris-versicolor has a wider IQR compared to Iris-setosa, indicating greater variation in petal length. There’s one outlier at 3.0.\n",
    "\n",
    "- **Class: Iris-virginica**\n",
    "  - Median: 5.6\n",
    "  - IQR: 0.80 (Q1: 5.1, Q3: 5.9)\n",
    "  - Outliers: None\n",
    "  - **Comment:** Iris-virginica shows the largest petal length median and a relatively larger IQR, indicating more diversity in petal lengths compared to the other classes.\n",
    "\n",
    "---\n",
    "\n",
    "### Feature: **Petal Width**\n",
    "\n",
    "- **Class: Iris-setosa**\n",
    "  - Median: 0.2\n",
    "  - IQR: 0.10 (Q1: 0.2, Q3: 0.3)\n",
    "  - Outliers: [0.5, 0.6]\n",
    "  - **Comment:** The petal width for Iris-setosa is quite small, with a narrow IQR. However, the outliers suggest there may be some rare cases with much larger petals.\n",
    "\n",
    "- **Class: Iris-versicolor**\n",
    "  - Median: 1.3\n",
    "  - IQR: 0.30 (Q1: 1.2, Q3: 1.5)\n",
    "  - Outliers: None\n",
    "  - **Comment:** Iris-versicolor has a moderate petal width with a consistent distribution and no outliers, indicating relatively stable measurements within the class.\n",
    "\n",
    "- **Class: Iris-virginica**\n",
    "  - Median: 2.0\n",
    "  - IQR: 0.50 (Q1: 1.8, Q3: 2.3)\n",
    "  - Outliers: None\n",
    "  - **Comment:** Petal width for Iris-virginica is the largest, indicating this class typically has broader petals compared to the others, with no outliers.\n",
    "\n",
    "---\n",
    "\n",
    "### General Observations:\n",
    "- **Iris-setosa** has smaller values for most features, especially petal width, but there are some outliers that may indicate some variation in the data.\n",
    "- **Iris-versicolor** is between the other two species in terms of median values and has a relatively consistent distribution across all features with only one outlier in petal length.\n",
    "- **Iris-virginica** tends to have the largest values for sepal length, petal length and width, indicating it generally has longer sepals and larger floral structures compared to the other classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pca'></a>\n",
    "#### Scatter Plot with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are four attributes that make it hard to visualise the whole dataset in one plot, we may want to use [*Principal Component Analysis* (PCA)](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:30.804806Z",
     "start_time": "2025-01-09T10:22:30.801197Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# principal compomemt analysis\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:30.817312Z",
     "start_time": "2025-01-09T10:22:30.804806Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# create PCA model with 2 components\n",
    "pca = PCA(n_components=2)\n",
    "# apply PCA to numerical data\n",
    "pca_result = pca.fit_transform(data_cleaned[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Create a DataFrame `pca_df` containing the result of PCA. This DataFrame should contain 2 columns: `PC1` and `PC2`\n",
    "* Create a new DataFrame `data_cleaned_pca` by contactenating `data_cleaned` and `pca_df`. Mind that the index of `data_cleaned` has been modified during the cleaning step. Reset the index before concatenation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:30.841486Z",
     "start_time": "2025-01-09T10:22:30.817312Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "pca_df = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])\n",
    "\n",
    "data_cleaned_reset = data_cleaned.reset_index(drop=True)\n",
    "data_cleaned_pca = pd.concat([data_cleaned_reset, pca_df], axis=1)\n",
    "data_cleaned_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:30.845651Z",
     "start_time": "2025-01-09T10:22:30.841486Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# create interactive plots\n",
    "import plotly.express as px "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:30.896430Z",
     "start_time": "2025-01-09T10:22:30.846868Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "fig = px.scatter(\n",
    "        data_cleaned_pca,\n",
    "        x='PC1',\n",
    "        y='PC2',\n",
    "        color='class',\n",
    "        title='PCA visualization of all flowers'\n",
    ")\n",
    "# Add variance explained\n",
    "var_explained = pca.explained_variance_ratio_\n",
    "fig.update_layout(\n",
    "        xaxis_title=f\"PC1 ({var_explained[0]:.1%} variance explained)\",\n",
    "        yaxis_title=f\"PC2 ({var_explained[1]:.1%} variance explained)\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the contributions of each feature to principal components, let's see the loadings. Loadings are given by `eigenvectors * sqrt(explained variance)` (Eigenvectors are unit-scaled loadings. They show direction of maximum variance). Basically, loadings are the correlations between variables and components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:30.901892Z",
     "start_time": "2025-01-09T10:22:30.896430Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# numeric calculations\n",
    "import numpy as np\n",
    "eigenvectors = pca.components_\n",
    "eigenvectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Calculate PCA `loadings`\n",
    "* Create a DataFrame for them. Display this DataFrame\n",
    "* Comment on the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:30.912334Z",
     "start_time": "2025-01-09T10:22:30.903412Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "loadings = eigenvectors.T * np.sqrt(cumulative_explained_variance)  # Transpose eigenvectors to match the number of features\n",
    "\n",
    "loadings_df = pd.DataFrame(loadings, columns=['PC1', 'PC2'], index=['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width'])\n",
    "\n",
    "print(loadings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR COMMENT: \n",
    "* PC1 is mainly influenced by Petal Length, with moderate contributions from Petal Width and Sepal Length.  \n",
    "* PC2 is driven by Sepal Length and Sepal Width, with minimal influence from Petal Length and Petal Width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task #3: Prepare Data for Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create clusters without the use of `class` attribute. So let's drop this column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Create a DataFrame `df_clustering` by droping the column `class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:30.926664Z",
     "start_time": "2025-01-09T10:22:30.912334Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "df_clustering = data_cleaned.drop(columns=['class'])\n",
    "df_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though in our case the attributes have comparable scales, let's apply a [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Recall, that for a given value `x`, a standard score is given by $z = \\frac{x - mean(\\mathbf{x})}{std(\\mathbf{x})}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:30.933708Z",
     "start_time": "2025-01-09T10:22:30.926664Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# scaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:30.973469Z",
     "start_time": "2025-01-09T10:22:30.933708Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df_clustering)\n",
    "# show\n",
    "print(scaled_data)\n",
    "# create a DataFrame\n",
    "scaled_data_df = pd.DataFrame(data=scaled_data, columns=df_clustering.columns)\n",
    "scaled_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task #4: Apply k-means Clustering and Find the Optimal Number of Clusters using Elbow Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply **k-means clustering**, we are going to use [`sklearn.cluster.KMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html). \n",
    "\n",
    "Mind that this algorithm requires a number of clusters as a parameter `k`. Let's first try `k=3` and then find the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:28:00.272926Z",
     "start_time": "2025-01-09T10:28:00.267338Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# k-means\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:28:02.222778Z",
     "start_time": "2025-01-09T10:28:02.202443Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# number of clusters \n",
    "k = 3\n",
    "# create a model\n",
    "kmeans = KMeans(n_clusters=k, init='k-means++')\n",
    "# fit scaled data\n",
    "kmeans.fit(scaled_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the associated labels using `labels_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:28:05.040025Z",
     "start_time": "2025-01-09T10:28:05.034879Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# associated cluster labels\n",
    "labels = kmeans.labels_\n",
    "print(f\"k-means labels: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the sum of squared distances of samples to their closest cluster center, use `inertia_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:28:07.383989Z",
     "start_time": "2025-01-09T10:28:07.375681Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# sum of squared distances\n",
    "inertia = kmeans.inertia_\n",
    "print(f\"Sum of squared distances: {inertia}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value can be used for finding the optimal number of clusters using the *Elbow method*. To do that let's vary the number of clusters `k`, apply k-means algorithm and store the corresponding intertia values. Then, let's plot the result and determine the best `k`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Find the optimal `k` using Elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:28:09.728549Z",
     "start_time": "2025-01-09T10:28:09.483722Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "inertia_values = []\n",
    "k_range = range(1, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, init='k-means++')\n",
    "    kmeans.fit(scaled_data_df)  # Fit the scaled data\n",
    "    inertia_values.append(kmeans.inertia_)\n",
    "\n",
    "# Plot inertia values to visualize the \"elbow\"\n",
    "plt.plot(k_range, inertia_values, marker='o')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia (Sum of squared distances)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR COMMENT: \n",
    "The sharp decrease occurs up to 𝑘=3, after it the rate of decrease slows down significantly.\n",
    "Elbow Point: k=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Add a column `cluster kmeans` to the `data_cleaned` DataFrame containing the labels of k-means clustering for `k=3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:28:12.494166Z",
     "start_time": "2025-01-09T10:28:12.459983Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "data_cleaned['cluster kmeans'] = labels\n",
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:31.209077Z",
     "start_time": "2025-01-09T10:22:31.171348Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# # Display some rows from each cluster\n",
    "# for cluster_label in data_cleaned['cluster kmeans'].unique():\n",
    "#     print(f\"Cluster {cluster_label}:\")\n",
    "#     print(data_cleaned[data_cleaned['cluster kmeans'] == cluster_label].head())  \n",
    "#     print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:31.218193Z",
     "start_time": "2025-01-09T10:22:31.209077Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "# pca_result = pca.fit_transform(scaled_data_df)\n",
    "# \n",
    "# pca_df = pd.DataFrame(data=pca_result, columns=['PCA1', 'PCA2'])\n",
    "# pca_df['Cluster'] = data_cleaned['cluster kmeans']\n",
    "# \n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for cluster_label in pca_df['Cluster'].unique():\n",
    "#     cluster_data = pca_df[pca_df['Cluster'] == cluster_label]\n",
    "#     plt.scatter(cluster_data['PCA1'], cluster_data['PCA2'], label=f'Cluster {cluster_label}', alpha=0.7)\n",
    "# \n",
    "# plt.title('Cluster Visualization with PCA', fontsize=14)\n",
    "# plt.xlabel('PCA1', fontsize=12)\n",
    "# plt.ylabel('PCA2', fontsize=12)\n",
    "# plt.legend()\n",
    "# plt.grid(alpha=0.3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the quality of the clustering, we can use **Silhouette Coefficient**. The Silhouette Coefficient for a sample is given by $(b - a) / max(a, b)$ where `b` is the distance between a sample and the nearest cluster that the sample is not a part of, and `a` is the mean intra-cluster distance (i.e. the mean distance between a sample and all other samples in the same cluster). \n",
    "\n",
    "The silhouette score ranges from -1 to 1 and indicates how well each data point fits within its assigned cluster:\n",
    "\n",
    "* Score near +1 means:\n",
    "    - The data point is far from neighboring clusters\n",
    "    - The point is well-matched to its cluster\n",
    "    - Indicates very distinct, well-separated clustering\n",
    "* Score near 0 means:\n",
    "    - The data point is close to the decision boundary between clusters\n",
    "    - The point could potentially belong to either cluster\n",
    "    - Suggests overlapping or not well-defined clusters\n",
    "* Score near -1 means:\n",
    "    - The data point might be assigned to the wrong cluster\n",
    "    - The point is closer to points in another cluster than its own\n",
    "    - Indicates poor clustering or potential misassignments\n",
    "\n",
    "We can use [`sklearn.metrics.silhouette_score`](https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.silhouette_score.html) and [`sklearn.metrics.silhouette_samples`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_samples.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:28:17.978101Z",
     "start_time": "2025-01-09T10:28:17.972622Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# silhouette scores\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* For k-means clustering with `k=3`, calculate Silhouette score for each data point, for each cluster and average silhouette score \n",
    "* Display Silhouette score plot\n",
    "* Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:28:20.365506Z",
     "start_time": "2025-01-09T10:28:20.340293Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "# Calculate the silhouette scores for each data point\n",
    "silhouette_values = silhouette_samples(scaled_data_df, labels)\n",
    "data_cleaned['silhouette_score'] = silhouette_values\n",
    "\n",
    "silhouette_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:28:23.431768Z",
     "start_time": "2025-01-09T10:28:23.406456Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "average_silhouette_score = silhouette_score(scaled_data_df, labels)\n",
    "print(f\"Average Silhouette Score: {average_silhouette_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:28:26.105434Z",
     "start_time": "2025-01-09T10:28:26.085335Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "cluster_silhouette_scores = data_cleaned.groupby('cluster kmeans')['silhouette_score'].mean()\n",
    "print(\"\\nAverage Silhouette Score per Cluster:\")\n",
    "print(cluster_silhouette_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:28:29.453590Z",
     "start_time": "2025-01-09T10:28:29.176516Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "k=3\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Sort silhouette scores within each cluster\n",
    "y_lower = 10  # Initial vertical position\n",
    "for i in range(k):\n",
    "    # Extract silhouette scores for cluster `i`\n",
    "    cluster_silhouette_values = silhouette_values[labels == i]\n",
    "    cluster_silhouette_values.sort()\n",
    "\n",
    "    # Determine the size of the cluster\n",
    "    cluster_size = cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + cluster_size\n",
    "\n",
    "    # Fill the silhouette plot for cluster `i`\n",
    "    ax.fill_betweenx(\n",
    "        np.arange(y_lower, y_upper),\n",
    "        0,\n",
    "        cluster_silhouette_values,\n",
    "        alpha=0.7,\n",
    "        label=f'Cluster {i}',\n",
    "    )\n",
    "\n",
    "    # Label the silhouette plots\n",
    "    ax.text(-0.05, y_lower + 0.5 * cluster_size, str(i))\n",
    "\n",
    "    # Update y_lower for the next cluster\n",
    "    y_lower = y_upper + 10\n",
    "\n",
    "# Add titles, labels, and legend\n",
    "ax.set_title(\"Silhouette Plot for k-Means Clustering\", fontsize=14)\n",
    "ax.set_xlabel(\"Silhouette Coefficient\", fontsize=12)\n",
    "ax.set_ylabel(\"Cluster\", fontsize=12)\n",
    "ax.axvline(x=average_silhouette_score, color=\"red\", linestyle=\"--\", label=\"Average Silhouette Score\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As general guidelines, the plot can be interpreted by looking at:\n",
    "* *the thickness of the clusters (number of points)*;\n",
    "* check if any cluster has many negative values;\n",
    "* check the consistency of the silhouette widths within clusters;\n",
    "* the average value. Recall that in general, the following interpretation applies:\n",
    "    - \\> 0.7: Strong clustering structure\n",
    "    - 0.5 - 0.7: Reasonable clustering structure\n",
    "    - 0.25 - 0.5: Weak clustering structure\n",
    "    - < 0.25: No substantial clustering structure\n",
    "* Cluster Silhouette scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All clusters appear to have similar thickness. Cluster 2 contains some negative points, suggesting that samples may have been misassigned. The values in cluster 1 are consistent, whereas clusters 0 and 2 show more variation among the samples. The average Silhouette Score of 0.4589 indicates a weak clustering structure.\n",
    "\n",
    "Average Silhouette Score per Cluster:\n",
    "cluster kmeans\n",
    "0    0.385937\n",
    "1    0.648810\n",
    "2    0.349509\n",
    "Cluster 1 has a good silhouette score, indicating strong cohesion and separation. In contrast, clusters 0 and 2 have lower scores, pointing to weaker separation and less cohesive grouping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Apply Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Apply Agglomerative clustering with different linkage options: complete, average, single. \n",
    "\n",
    "*Hint*: use [`sklearn.cluster.AgglomerativeClustering`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)\n",
    "* For each linkage, draw a dendrogram.\n",
    "* Calculate the silhouette scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:29:52.526220Z",
     "start_time": "2025-01-09T10:29:52.514797Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:29:58.121346Z",
     "start_time": "2025-01-09T10:29:55.207570Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "linkage_methods = ['complete', 'average', 'single']\n",
    "\n",
    "for method in linkage_methods:\n",
    "    linked = linkage(scaled_data_df, method=method)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    dendrogram(linked)\n",
    "    plt.title(f\"Dendrogram - {method} linkage\")\n",
    "    plt.xlabel('Sample index')\n",
    "    plt.ylabel('Distance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:30:09.417379Z",
     "start_time": "2025-01-09T10:30:09.395595Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "silhouette_scores = {}\n",
    "\n",
    "for method in linkage_methods:\n",
    "    agglomerative_clustering = AgglomerativeClustering(linkage=method)\n",
    "    \n",
    "    labels = agglomerative_clustering.fit_predict(scaled_data_df)\n",
    "    \n",
    "    score = silhouette_score(scaled_data_df, labels)\n",
    "    silhouette_scores[method] = score\n",
    "    print(f\"Silhouette score for linkage {method}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Apply DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Apply [sklearn.cluster.DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html) algorithm\n",
    "* Identify the best values for `eps` and `min_sanples` by varying the values within a range and by using Silhouette coefficient\n",
    "* Apply DBSCAN with the best parameters found\n",
    "* Print number of clusters and noise points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:30:14.733079Z",
     "start_time": "2025-01-09T10:30:14.727270Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# DBSCAN\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:30:25.561354Z",
     "start_time": "2025-01-09T10:30:24.764102Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "eps_values = np.arange(0.1, 2.1, 0.1)\n",
    "min_samples_values = range(3, 10)\n",
    "\n",
    "best_score = -1\n",
    "best_eps = None\n",
    "best_min_samples = None\n",
    "\n",
    "for eps in eps_values:\n",
    "    for min_samples in min_samples_values:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(scaled_data_df)\n",
    "        \n",
    "        # Ignore cases where all points are labeled as noise (label == -1)\n",
    "        if len(set(labels)) > 1:\n",
    "            score = silhouette_score(scaled_data_df, labels)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_eps = eps\n",
    "                best_min_samples = min_samples\n",
    "            print(f\"eps: {eps}, min_samples: {min_samples}, Silhouette score: {score}\")\n",
    "\n",
    "print(f\"\\nBest parameters - eps: {best_eps}, min_samples: {best_min_samples}, Silhouette score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:30:30.806606Z",
     "start_time": "2025-01-09T10:30:30.786304Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "dbscan_best = DBSCAN(eps=best_eps, min_samples=best_min_samples)\n",
    "labels_best = dbscan_best.fit_predict(scaled_data_df)\n",
    "\n",
    "n_clusters = len(set(labels_best)) - (1 if -1 in labels_best else 0)\n",
    "\n",
    "n_noise = list(labels_best).count(-1)\n",
    "\n",
    "print(f\"\\nNumber of clusters: {n_clusters}\")\n",
    "print(f\"Number of noise points: {n_noise}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Cluster Characterisation using Apriori algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we would like to describe the obtained cluster. To do so, let's use frequent pattern mining and in particular **Apriori algorithm**. \n",
    "\n",
    "**QUESTIONS**\n",
    "* First, convert numerical features to categorical (low, medium, high) based on quantiles. Add binary columns, e.g. `sepal length low`, `sepal length medium`, `sepal length high` depending on the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:31:06.088791Z",
     "start_time": "2025-01-09T10:31:06.033470Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "def categorize_feature(df, feature, quantiles=[0.33, 0.67]):\n",
    "    quantile_values = df[feature].quantile(quantiles).values\n",
    "    labels = ['low', 'medium', 'high']\n",
    "    \n",
    "    categorized = pd.cut(df[feature], bins=[-float('inf')] + list(quantile_values) + [float('inf')], \n",
    "                         labels=labels, include_lowest=True)\n",
    "    return categorized\n",
    "\n",
    "numerical_features = ['sepal length', 'sepal width', 'petal length', 'petal width']  # Example features, adjust as needed\n",
    "\n",
    "data_transformed = data_cleaned.copy()\n",
    "\n",
    "for feature in numerical_features:\n",
    "    data_transformed[f'{feature} categorical'] = categorize_feature(data_cleaned, feature)\n",
    "\n",
    "for feature in numerical_features:\n",
    "    for category in ['low', 'medium', 'high']:\n",
    "        data_transformed[f'{feature} {category}'] = (data_transformed[f'{feature} categorical'] == category).astype(int)\n",
    "\n",
    "data_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find association, we are going to use [mlxtend.frequent_patterns.apriori](https://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:31:13.637444Z",
     "start_time": "2025-01-09T10:31:13.631708Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# frequent patterns\n",
    "from mlxtend.frequent_patterns import apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Use apriori algorithm to find frequent patterns for each cluster\n",
    "* Then among these itemsets, find those that are not frequent for other clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:34.622781Z",
     "start_time": "2025-01-09T10:22:34.608456Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "data_transformed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:31:18.516022Z",
     "start_time": "2025-01-09T10:31:18.470539Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "def find_frequent_patterns_for_cluster(df, cluster_label):\n",
    "    cluster_df = df[df['cluster kmeans'] == cluster_label]\n",
    "    columns_to_drop = ['sepal length', 'sepal width', 'petal length', 'petal width',\n",
    "                   'class', 'cluster kmeans', 'silhouette_score', \n",
    "                   'sepal length categorical', 'sepal width categorical', \n",
    "                   'petal length categorical', 'petal width categorical']\n",
    "\n",
    "    cluster_df = cluster_df.drop(columns=columns_to_drop)\n",
    "    frequent_itemsets = apriori(cluster_df, min_support=0.1, use_colnames=True)\n",
    "    return frequent_itemsets\n",
    "\n",
    "frequent_itemsets_by_cluster = {}\n",
    "for cluster_label in data_transformed['cluster kmeans'].unique():\n",
    "    frequent_itemsets_by_cluster[cluster_label] = find_frequent_patterns_for_cluster(data_transformed, cluster_label)\n",
    "    \n",
    "for cluster_label, itemsets in frequent_itemsets_by_cluster.items():\n",
    "    print(f\"Frequent itemsets for Cluster {cluster_label}:\")\n",
    "    print(itemsets.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:31:40.110852Z",
     "start_time": "2025-01-09T10:31:40.076497Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "unique_itemsets_by_cluster = {}\n",
    "\n",
    "for cluster_label, itemsets in frequent_itemsets_by_cluster.items():\n",
    "    unique_itemsets = itemsets.copy()\n",
    "    for other_label, other_itemsets in frequent_itemsets_by_cluster.items():\n",
    "        if cluster_label != other_label:\n",
    "            common_itemsets = pd.merge(unique_itemsets, other_itemsets, how='inner', on='itemsets')\n",
    "            unique_itemsets = unique_itemsets[~unique_itemsets['itemsets'].isin(common_itemsets['itemsets'])]\n",
    "\n",
    "    unique_itemsets_by_cluster[cluster_label] = unique_itemsets\n",
    "\n",
    "for cluster_label, unique_itemsets in unique_itemsets_by_cluster.items():\n",
    "    print(f\"Unique frequent itemsets for Cluster {cluster_label}:\")\n",
    "    print(unique_itemsets.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:34.680922Z",
     "start_time": "2025-01-09T10:22:34.677377Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
